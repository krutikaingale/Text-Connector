{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import gensim\n",
    "import nltk\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "\n",
    "This lesson is designed to explore features of word embeddings described by Ben Schmidt in his blog post <a href=\"http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html\">\"Rejecting the Gender Binary\"</a>.\n",
    "\n",
    "The primary corpus we use consists of the <a href=\"http://txtlab.org/?p=601\">150 English-language novels</a> made available by the .txtLab at McGill. We also look at a <a href=\"http://ryanheuser.org/word-vectors-1/\">Word2Vec model trained on the ECCO-TCP corpus</a> of 2,350 eighteenth-century literary texts made available by Ryan Heuser. (I have shortened the number of terms in the model by half in order to conserve memory.)\n",
    "\n",
    "For background on Word2Vec's mechanics, I suggest this <a href=\"https://www.tensorflow.org/versions/r0.8/tutorials/word2vec/index.html\">brief tutorial</a> by Google, especially the sections \"Motivation,\" \"Skip-Gram Model,\" and \"Visualizing.\"\n",
    "\n",
    "We'll read in Andrew Piper's corpus we used in our Topic Modeling notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_tb = Table.read_table('../09-Topic-Modeling/data/txtlab_Novel150_English.csv')\n",
    "\n",
    "fiction_path = '../09-Topic-Modeling/data/txtlab_Novel150_English/'\n",
    "\n",
    "novel_list = []\n",
    "\n",
    "# Iterate through filenames in metadata table\n",
    "for filename in metadata_tb['filename']:\n",
    "    \n",
    "    # Read in novel text as single string, make lowercase\n",
    "    with open(fiction_path + filename, 'r') as file_in:\n",
    "        novel = file_in.read()\n",
    "    \n",
    "    # Add novel text as single string to master list\n",
    "    novel_list.append(novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Pre-Processing\n",
    "\n",
    "Word2Vec learns about the relationships among words by observing them in context. We'll need to tokenize the words in our corpus while retaining sentence boundaries. Since novels were imported as single strings, we'll first use <i>sent_tokenize</i> to divide them into sentences, and second, we'll split each sentence into its own list of words.\n",
    "\n",
    "We'll use `nltk`'s sentence tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to memory and time constraints we'll use our quick and dirty tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_tokenize(text):\n",
    "    \n",
    "    # Iterate through text removing punctuation characters\n",
    "    no_punct = \"\".join([char for char in text if char not in punctuation])\n",
    "    \n",
    "    # Split text over whitespace into list of words\n",
    "    tokens = no_punct.split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence for novel in novel_list for sentence in sent_tokenize(novel)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_sentence = [fast_tokenize(sentence.lower()) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll double check that we don't have any empty sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_sentence = [sentence for sentence in words_by_sentence if sentence != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have a `list` of `list`s with sentences and words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['author’s',\n",
       "  'introduction',\n",
       "  'my',\n",
       "  'dog',\n",
       "  'had',\n",
       "  'made',\n",
       "  'a',\n",
       "  'point',\n",
       "  'on',\n",
       "  'a',\n",
       "  'piece',\n",
       "  'of',\n",
       "  'fallowground',\n",
       "  'and',\n",
       "  'led',\n",
       "  'the',\n",
       "  'curate',\n",
       "  'and',\n",
       "  'me',\n",
       "  'two',\n",
       "  'or',\n",
       "  'three',\n",
       "  'hundred',\n",
       "  'yards',\n",
       "  'over',\n",
       "  'that',\n",
       "  'and',\n",
       "  'some',\n",
       "  'stubble',\n",
       "  'adjoining',\n",
       "  'in',\n",
       "  'a',\n",
       "  'breathless',\n",
       "  'state',\n",
       "  'of',\n",
       "  'expectation',\n",
       "  'on',\n",
       "  'a',\n",
       "  'burning',\n",
       "  'first',\n",
       "  'of',\n",
       "  'september'],\n",
       " ['it',\n",
       "  'was',\n",
       "  'a',\n",
       "  'false',\n",
       "  'point',\n",
       "  'and',\n",
       "  'our',\n",
       "  'labour',\n",
       "  'was',\n",
       "  'vain',\n",
       "  'yet',\n",
       "  'to',\n",
       "  'do',\n",
       "  'rover',\n",
       "  'justice',\n",
       "  'for',\n",
       "  'he’s',\n",
       "  'an',\n",
       "  'excellent',\n",
       "  'dog',\n",
       "  'though',\n",
       "  'i',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'his',\n",
       "  'pedigree',\n",
       "  'the',\n",
       "  'fault',\n",
       "  'was',\n",
       "  'none',\n",
       "  'of',\n",
       "  'his',\n",
       "  'the',\n",
       "  'birds',\n",
       "  'were',\n",
       "  'gone',\n",
       "  'the',\n",
       "  'curate',\n",
       "  'showed',\n",
       "  'me',\n",
       "  'the',\n",
       "  'spot',\n",
       "  'where',\n",
       "  'they',\n",
       "  'had',\n",
       "  'lain',\n",
       "  'basking',\n",
       "  'at',\n",
       "  'the',\n",
       "  'root',\n",
       "  'of',\n",
       "  'an',\n",
       "  'old',\n",
       "  'hedge']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_by_sentence[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Word2Vec\n",
    "\n",
    "### Word Embeddings\n",
    "Word2Vec is the most prominent word embedding algorithm. Word embedding generally attempts to identify semantic relationships between words by observing them in context.\n",
    "\n",
    "Imagine that each word in a novel has its meaning determined by the ones that surround it in a limited window. For example, in Moby Dick's first sentence, “me” is paired on either side by “Call” and “Ishmael.” After observing the windows around every word in the novel (or many novels), the computer will notice a pattern in which “me” falls between similar pairs of words to “her,” “him,” or “them.” Of course, the computer had gone through a similar process over the words “Call” and “Ishmael,” for which “me” is reciprocally part of their contexts.  This chaining of signifiers to one another mirrors some of humanists' most sophisticated interpretative frameworks of language.\n",
    "\n",
    "The two main flavors of Word2Vec are CBOW (Continuous Bag of Words) and Skip-Gram, which can be distinguished partly by their input and output during training. Skip-Gram takes a word of interest as its input (e.g. \"me\") and tries to learn how to predict its context words (\"Call\",\"Ishmael\"). CBOW does the opposite, taking the context words (\"Call\",\"Ishmael\") as a single input and tries to predict the word of interest (\"me\").\n",
    "\n",
    "In general, CBOW is is faster and does well with frequent words, while Skip-Gram potentially represents rare words better.\n",
    "\n",
    "### Word2Vec Features\n",
    "<ul>\n",
    "<li>`size`: Number of dimensions for word embedding model</li>\n",
    "<li>`window`: Number of context words to observe in each direction</li>\n",
    "<li>`min_count`: Minimum frequency for words included in model</li>\n",
    "<li>`sg` (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram</li>\n",
    "<li>`alpha`: Learning rate (initial); prevents model from over-correcting, enables finer tuning</li>\n",
    "<li>`iterations`: Number of passes through dataset</li>\n",
    "<li>`batch_words`: Number of words to sample from data during each pass</li>\n",
    "</ul>\n",
    "\n",
    "Note: cell below uses default value for each argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We've gotten accustomed to training powerful models in Python with one line of code, why stop now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words_by_sentence, size=100, window=5, \\\n",
    "                               min_count=5, sg=0, alpha=0.025, iter=5, batch_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "We can return the actual high-dimensional vector by simply indexing the model with the word as the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.27336550e+00,  -4.96827871e-01,   3.96743596e-01,\n",
       "        -3.90099287e-01,  -4.04696584e-01,  -1.23449183e+00,\n",
       "         1.39637733e+00,   4.62491244e-01,   1.58219969e+00,\n",
       "        -5.53411067e-01,  -1.36463618e+00,   1.08154547e+00,\n",
       "        -9.71694589e-01,  -1.02774096e+00,   8.59629214e-01,\n",
       "         7.48246253e-01,   1.62878668e+00,   2.23547637e-01,\n",
       "         9.85610187e-01,  -1.81456971e+00,  -8.64322603e-01,\n",
       "        -1.24552023e+00,   1.49370337e+00,  -1.45119265e-01,\n",
       "        -3.79700422e-01,  -6.21708925e-04,  -1.33703578e+00,\n",
       "         1.00775259e-02,  -1.61727870e+00,   6.15913868e-01,\n",
       "        -1.25048852e+00,  -1.99238622e+00,  -9.06213224e-01,\n",
       "        -1.53188419e+00,   1.13445795e+00,  -4.77040410e-01,\n",
       "         6.68763041e-01,   1.54968128e-01,  -6.64280713e-01,\n",
       "        -1.91718864e+00,  -1.76358968e-01,   8.62981603e-02,\n",
       "        -6.27527833e-01,   1.51731655e-01,   6.20771885e-01,\n",
       "        -9.69930351e-01,  -7.12331057e-01,  -7.20959425e-01,\n",
       "        -4.88411248e-01,  -4.80336428e-01,  -8.90503824e-01,\n",
       "         5.41046023e-01,   3.36504221e-01,  -2.07781005e+00,\n",
       "        -8.48483503e-01,   2.19694471e+00,   1.19486248e+00,\n",
       "        -2.02422142e+00,  -3.16767383e+00,  -1.74479592e+00,\n",
       "        -1.71999300e+00,   6.20566130e-01,  -2.07016802e+00,\n",
       "         1.91076487e-01,  -8.51029932e-01,  -2.30918884e+00,\n",
       "        -2.41313219e+00,  -5.75865805e-01,   1.94943815e-01,\n",
       "        -9.93286729e-01,  -1.59864053e-01,   1.49666238e+00,\n",
       "        -1.11748874e+00,   6.03066742e-01,   3.46750557e-01,\n",
       "         5.76419353e-01,   1.36762142e+00,  -2.10567021e+00,\n",
       "        -7.74325371e-01,  -1.91926122e-01,   6.78545654e-01,\n",
       "        -8.80982399e-01,  -5.43744385e-01,   7.38245666e-01,\n",
       "        -7.04399645e-01,  -7.41061807e-01,  -7.53516197e-01,\n",
       "        -2.89858013e-01,  -7.69380689e-01,  -1.75324416e+00,\n",
       "        -1.00003886e+00,  -4.54814315e-01,  -8.06956947e-01,\n",
       "         6.62631035e-01,  -2.72192061e-01,   1.10772097e+00,\n",
       "        -3.10187675e-02,   1.85486960e+00,  -1.25594175e+00,\n",
       "        -4.47889686e-01], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['whale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gensim` comes with some handy methods to analyze word relationships. `similarity` will give us a number from 0-1 based on how similar two words are. If this sounds like cosine similarity for words, you'd be right! It just takes the cosine similarity of these high dimensional vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64836012480569127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('sense','sensibility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find cosine distance between two clusters of word vectors. Each cluster is measured as the mean of its words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12442688875556145"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity(['sense','sensibility'],['whale','harpoon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find words that don't belong with `doesnt_match`. It finds the mean vector of the words in the `list`, and identifies the furthest away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harpoon'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(['pride','prejudice', 'harpoon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most famous implementation of this vector math is semantics. What happens if we take:\n",
    "\n",
    "$$King - Man + Woman = $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('princess', 0.7416763305664062),\n",
       " ('queen', 0.7214570045471191),\n",
       " ('saint', 0.6903055310249329),\n",
       " ('duke', 0.6820172071456909),\n",
       " ('emperor', 0.6537982821464539),\n",
       " ('duchess', 0.6393168568611145),\n",
       " ('priest', 0.6311855912208557),\n",
       " ('virgin', 0.6294018030166626),\n",
       " ('conqueror', 0.6254926919937134),\n",
       " ('abbot', 0.6240617036819458)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schmidt looked at words associated with male and female pronouns to investigate gender. Let's try take all the female pronouns and subtracting the male pronouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovely', 0.502685546875),\n",
       " ('maiden', 0.47776973247528076),\n",
       " ('beautiful', 0.4759494662284851),\n",
       " ('miss', 0.46963489055633545),\n",
       " ('beauty', 0.4566827714443207),\n",
       " ('sweet', 0.43204039335250854),\n",
       " ('innocent', 0.4234784245491028),\n",
       " ('girlish', 0.42034807801246643),\n",
       " ('anne', 0.4179074168205261),\n",
       " ('charms', 0.4139993488788605)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['she','her','hers','herself'], negative=['he','him','his','himself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the opposite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horse', 0.4664072096347809),\n",
       " ('moby', 0.44690239429473877),\n",
       " ('bill', 0.43676984310150146),\n",
       " ('lazarus', 0.41751667857170105),\n",
       " ('ahab', 0.415912389755249),\n",
       " ('manfully', 0.4150606393814087),\n",
       " ('captain', 0.41503840684890747),\n",
       " ('clerk', 0.41258805990219116),\n",
       " ('steward', 0.4109916388988495),\n",
       " ('cyril', 0.41083717346191406)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about together (*genderless* in Schmidt's sense)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edgar', 0.6176052093505859),\n",
       " ('camilla', 0.5952227115631104),\n",
       " ('antonia', 0.5951999425888062),\n",
       " ('them', 0.5831330418586731),\n",
       " ('itself', 0.5744680166244507),\n",
       " ('eugenia', 0.570426344871521),\n",
       " ('it', 0.5593734383583069),\n",
       " ('adeline', 0.5567945241928101),\n",
       " ('margaret', 0.5535603761672974),\n",
       " ('carrie', 0.5433840155601501),\n",
       " ('eleanor', 0.5430295467376709),\n",
       " ('cora', 0.5408198833465576),\n",
       " ('savonarola', 0.5372533798217773),\n",
       " ('indiana', 0.5339543223381042),\n",
       " ('carwin', 0.5265582799911499),\n",
       " ('aileen', 0.5252206921577454),\n",
       " ('erica', 0.5229066014289856),\n",
       " ('elinor', 0.5226877927780151),\n",
       " ('amy', 0.5205459594726562),\n",
       " ('algernon', 0.5184049010276794),\n",
       " ('me', 0.5152862071990967),\n",
       " ('constraint', 0.515021800994873),\n",
       " ('catherine', 0.5102472901344299),\n",
       " ('munro', 0.5100835561752319),\n",
       " ('edward', 0.5094944834709167),\n",
       " ('clermont', 0.5048537850379944),\n",
       " ('isabel', 0.5034631490707397),\n",
       " ('valancourt', 0.5023504495620728),\n",
       " ('kim', 0.5022979974746704),\n",
       " ('leonora', 0.5018230676651001),\n",
       " ('magua', 0.5014692544937134),\n",
       " ('rhoda', 0.4991867244243622),\n",
       " ('illtemper', 0.49769389629364014),\n",
       " ('jo', 0.49644625186920166),\n",
       " ('disapprobation', 0.4948806166648865),\n",
       " ('marianne', 0.4927206039428711),\n",
       " ('maggie', 0.4910057783126831),\n",
       " ('heyward', 0.4904366135597229),\n",
       " ('rebecca', 0.4903925657272339),\n",
       " ('tess', 0.48777762055397034),\n",
       " ('lily', 0.4840327501296997),\n",
       " ('latter', 0.48146677017211914),\n",
       " ('duncan', 0.48063912987709045),\n",
       " ('belinda', 0.4805896282196045),\n",
       " ('agnes', 0.47870558500289917),\n",
       " ('welbeck', 0.47831636667251587),\n",
       " ('anxiety', 0.4755129814147949),\n",
       " ('cecilia', 0.473427951335907),\n",
       " ('aspasia', 0.47342580556869507),\n",
       " ('myself', 0.47164201736450195)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['she','her','hers','herself','he','him','his','himself'], topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Homework\n",
    "\n",
    "Use the `most_similar` method to find the tokens nearest to 'car' in our model. Do the same for 'motorcar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wagon', 0.8360811471939087),\n",
       " ('coach', 0.8272905349731445),\n",
       " ('cab', 0.8220912218093872),\n",
       " ('buggy', 0.8058090209960938),\n",
       " ('cart', 0.799831211566925),\n",
       " ('vehicle', 0.7998005747795105),\n",
       " ('barn', 0.7873604893684387),\n",
       " ('boat', 0.7845875024795532),\n",
       " ('sleigh', 0.7743357419967651),\n",
       " ('team', 0.7722744941711426)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seedcake', 0.7086451053619385),\n",
       " ('haystack', 0.7075169086456299),\n",
       " ('woodpile', 0.7016493082046509),\n",
       " ('roosted', 0.6933606863021851),\n",
       " ('squirt', 0.6862908601760864),\n",
       " ('cockleshell', 0.6830296516418457),\n",
       " ('sewer', 0.6827046275138855),\n",
       " ('hogshead', 0.6826945543289185),\n",
       " ('tendollar', 0.6799261569976807),\n",
       " ('spool', 0.6785520911216736)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['motorcar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What characterizes each word in our corpus? Does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity of the word to another word. This makes sense, because each word's similarity to another can be quantified using the cosine similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vector addition and subtraction can be thought of in terms of analogy. From the example above: 'man' is to 'king' as 'woman' is to '???'. Use the `most_similar` method to find: 'paris' is to 'france' as 'london' is to '???'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('england', 0.7840549945831299),\n",
       " ('spain', 0.7614985108375549),\n",
       " ('america', 0.7572265863418579),\n",
       " ('italy', 0.7432318925857544),\n",
       " ('germany', 0.7313573956489563),\n",
       " ('scotland', 0.7202014923095703),\n",
       " ('india', 0.7055636644363403),\n",
       " ('europe', 0.6962637901306152),\n",
       " ('city', 0.6950817108154297),\n",
       " ('ireland', 0.6937568187713623)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['london', 'france'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What has our model learned about nation-states?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has learned that certain cities are more likely to be in certain countries. It correctly predicted that London is most similar to England, because London is a major city in London."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Perform the canonic Word2Vec addition again but leave out a term. Try 'king' - 'man', 'woman' - 'man', 'woman' + 'king'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sheba', 0.532245397567749),\n",
       " ('casimir', 0.49883437156677246),\n",
       " ('vespers', 0.49645933508872986),\n",
       " ('strelsau', 0.4915085434913635),\n",
       " ('medina', 0.49000799655914307),\n",
       " ('steyne', 0.489401638507843),\n",
       " ('wellington', 0.48672500252723694),\n",
       " ('macadams', 0.48476657271385193),\n",
       " ('royal', 0.4840894043445587),\n",
       " ('ruritania', 0.47716692090034485)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maiden', 0.5190343856811523),\n",
       " ('lovely', 0.480085164308548),\n",
       " ('beautiful', 0.47629043459892273),\n",
       " ('jane', 0.47506430745124817),\n",
       " ('susan', 0.46571850776672363),\n",
       " ('charming', 0.45558297634124756),\n",
       " ('penelope', 0.4548298120498657),\n",
       " ('maid', 0.4528403580188751),\n",
       " ('louisa', 0.45028048753738403),\n",
       " ('flowers', 0.44268670678138733)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('priest', 0.7774257063865662),\n",
       " ('jew', 0.7717772722244263),\n",
       " ('man', 0.7595362067222595),\n",
       " ('clergyman', 0.753511369228363),\n",
       " ('minister', 0.7329345941543579),\n",
       " ('nobleman', 0.7250956296920776),\n",
       " ('soldier', 0.7249808311462402),\n",
       " ('poet', 0.7185976505279541),\n",
       " ('princess', 0.7181243896484375),\n",
       " ('nun', 0.7125148773193359)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman','king'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What do these indicate semantically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression 'king' - 'man' would represent words that describe a king that isn't male. 'woman' - 'man' would mean words that are related to a woman and not to a man. 'woman' + 'king' would mean words that relate a woman and a king together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualization\n",
    "\n",
    "We can use multi-dimensional scaling to visualize this space just like we did with the documents before. But there are a lot of words here, so let's limit it to 50 words from our female gendered subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "her_tokens = [token for token,weight in model.most_similar(positive=['she','her','hers','herself'], \\\n",
    "                                                       negative=['he','him','his','himself'], topn=50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the vector from each word, just like above, and add that to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [model[word] for word in her_tokens]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate pairwise the cosine distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "dist_matrix = pairwise.pairwise_distances(vectors, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `MDS` to reduce the dimensions to two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components = 2, dissimilarity='precomputed')\n",
    "embeddings = mds.fit_transform(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some fancy `matplotlib` code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAJCCAYAAACbGlAnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3664701518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(figsize=(10,10))\n",
    "ax.scatter(embeddings[:,0], embeddings[:,1], alpha=0)\n",
    "for i in range(len(vectors)):\n",
    "    ax.annotate(her_tokens[i], ((embeddings[i,0], embeddings[i,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What kinds of semantic relationships exist in the diagram above? Are there any words that seem out of place? How do you think they go there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words in the diagram are very relate to femininity, girlishness, softness, fragileness, and more. Some words like \"husbands\" and \"harden\" seem out of place. Women, when talked about in 18th century novels, are likely to be talked about in relation to their husbands. The \"harden\" could be an error in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Saving/Loading Models\n",
    "\n",
    "We can save the model as a `.txt` file with the `save_word2vec_format` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('word2vec.txtalb_Novel150_English.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load up a model, we just ask `gensim`. Here's a model trained on Eighteenth Century Collections Online corpus (~2500 texts) made available by Ryan Heuser: http://ryanheuser.org/word-vectors-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_model = gensim.models.KeyedVectors.load_word2vec_format('data/word2vec.ECCO-TCP.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7854657173156738),\n",
       " ('emperor', 0.7523162364959717),\n",
       " ('prince', 0.7436755895614624),\n",
       " ('princess', 0.713316798210144),\n",
       " ('conqueror', 0.7111818194389343),\n",
       " ('regent', 0.7088087797164917),\n",
       " ('empress', 0.6977599263191223),\n",
       " ('sultan', 0.6729022264480591),\n",
       " ('confessor', 0.6569845676422119),\n",
       " ('duke', 0.6366889476776123)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"harriet's\", 0.5708541870117188),\n",
       " ('softness', 0.5513930320739746),\n",
       " ('maiden', 0.5411286354064941),\n",
       " (\"chloe's\", 0.5403314828872681),\n",
       " ('lovely', 0.5320479869842529),\n",
       " ('coy', 0.5259038209915161),\n",
       " ('bewitching', 0.5255858898162842),\n",
       " ('soft', 0.5217857956886292),\n",
       " ('blushing', 0.5112706422805786),\n",
       " ('virgin', 0.5070083141326904)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_model.most_similar(positive=['she','her','hers','herself'], negative=['he','him','his','himself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this differ from our novels model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations in this model are slightly a bit higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Homework\n",
    "\n",
    "Heuser's blog post explores an analogy in eighteenth-century thought that Riches are to Virtue what Learning is to Genius. How true is this in the ECCO-trained Word2Vec model? Is it true in the one we trained?\n",
    "\n",
    "How might we compare word2vec models more generally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('piety', 0.7372761368751526),\n",
       " ('morality', 0.7266900539398193),\n",
       " ('science', 0.6974709630012512),\n",
       " ('prudence', 0.6855395436286926),\n",
       " ('philosophy', 0.683079183101654),\n",
       " ('wisdom', 0.6511392593383789),\n",
       " ('genius', 0.6505820155143738),\n",
       " ('humanity', 0.640283465385437),\n",
       " ('modesty', 0.6369403004646301),\n",
       " ('morals', 0.6340599060058594)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_model.most_similar(positive=['learning', 'virtue'], negative=['riches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('religion', 0.6889680624008179),\n",
       " ('honesty', 0.6413684487342834),\n",
       " ('principle', 0.6331804990768433),\n",
       " ('philosophy', 0.6291975975036621),\n",
       " ('science', 0.6242105960845947),\n",
       " ('wisdom', 0.6162780523300171),\n",
       " ('doctrine', 0.6005883812904358),\n",
       " ('teaching', 0.5990396738052368),\n",
       " ('theory', 0.5936211943626404),\n",
       " ('religious', 0.592136025428772)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['learning', 'virtue'], negative=['riches'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is sort of true in the Word2Vec model, since 'genius' does appear in its list of most similar words. It is not true in our model, since 'genius' doesn't even appear in the list of most similar words. We can compare word2vec models more generally by seeing how their most similar words compare for multiple analogies. We can use multi-dimensional scaling to visualize the space of the two models for multiple analogies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Alternative features for a classification model\n",
    "\n",
    "This is really cool but what implications does this have for our model of language? Well, word embeddings are simply more precise features of what we've been trying to get at already. That means we can use them in the machine learning models we've been building.\n",
    "\n",
    "Recall our DTM bag of words classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /srv/app/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87250000000000005"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n",
    "judgements = [movie_reviews.categories(fileid)[0] for fileid in movie_reviews.fileids()]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = shuffle(reviews, judgements, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# get tfidf values\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(X)\n",
    "X_train_transformed = tfidf.transform(X_train)\n",
    "X_test_transformed = tfidf.transform(X_test)\n",
    "\n",
    "# build and test logit\n",
    "logit_class = LogisticRegression(penalty='l2', C=1000)\n",
    "logit_model = logit_class.fit(X_train_transformed, y_train)\n",
    "logit_model.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 39482)\t0.0149841414947\n",
      "  (0, 39474)\t0.0345030768233\n",
      "  (0, 39422)\t0.0213437436018\n",
      "  (0, 39396)\t0.0144544442222\n",
      "  (0, 39269)\t0.0181623328864\n",
      "  (0, 39203)\t0.020693033426\n",
      "  (0, 39200)\t0.0327929894208\n",
      "  (0, 39165)\t0.0435264547455\n",
      "  (0, 39031)\t0.0294531298824\n",
      "  (0, 39013)\t0.0135878605544\n",
      "  (0, 38952)\t0.0266019615532\n",
      "  (0, 38849)\t0.0172920457952\n",
      "  (0, 38835)\t0.0409828918483\n",
      "  (0, 38811)\t0.017847241143\n",
      "  (0, 38781)\t0.0374593599495\n",
      "  (0, 38711)\t0.0373990816522\n",
      "  (0, 38707)\t0.0219887830607\n",
      "  (0, 38699)\t0.0116541610458\n",
      "  (0, 38696)\t0.0174684430988\n",
      "  (0, 38614)\t0.272537175332\n",
      "  (0, 38610)\t0.0213487428512\n",
      "  (0, 38508)\t0.0304715119971\n",
      "  (0, 38426)\t0.0162050803548\n",
      "  (0, 38405)\t0.0255704404464\n",
      "  (0, 38285)\t0.0734220193703\n",
      "  :\t:\n",
      "  (1599, 3209)\t0.0596711477613\n",
      "  (1599, 2954)\t0.0190221047383\n",
      "  (1599, 2746)\t0.102125517201\n",
      "  (1599, 2662)\t0.0424659765486\n",
      "  (1599, 2514)\t0.0501023995268\n",
      "  (1599, 2440)\t0.036887758569\n",
      "  (1599, 2396)\t0.0101538207029\n",
      "  (1599, 2351)\t0.0344622523885\n",
      "  (1599, 2217)\t0.0435462900877\n",
      "  (1599, 2013)\t0.0232850244456\n",
      "  (1599, 2006)\t0.0169516220772\n",
      "  (1599, 1810)\t0.11718635374\n",
      "  (1599, 1615)\t0.0244658469867\n",
      "  (1599, 1599)\t0.0454699813425\n",
      "  (1599, 1579)\t0.0158445568749\n",
      "  (1599, 1559)\t0.0216703030391\n",
      "  (1599, 1501)\t0.0380565119638\n",
      "  (1599, 1256)\t0.0158718967537\n",
      "  (1599, 982)\t0.0229023960436\n",
      "  (1599, 966)\t0.045249923964\n",
      "  (1599, 719)\t0.0366545417173\n",
      "  (1599, 291)\t0.0581672886126\n",
      "  (1599, 229)\t0.0771511476748\n",
      "  (1599, 208)\t0.0469956369909\n",
      "  (1599, 194)\t0.105021421167\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So how can we use word embeddings as features? Believe it or not, one of the most effective ways is to simply average each dimension of our embedding across all the words for a given document. Recall our w2v model for novels was trained for 100 dimensions. Creating the features for a specific document would entail first extracting the 100 dimensions for each word, then average each dimension across all words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.53365397e-01,   7.29394972e-01,   4.46595043e-01,\n",
       "        -1.03898317e-01,  -4.01734024e-01,  -2.11622104e-01,\n",
       "        -3.09558809e-01,   4.17446285e-01,   7.61919320e-01,\n",
       "        -7.86552355e-02,  -1.87649921e-01,  -2.55803764e-01,\n",
       "        -2.25380257e-01,  -1.90770224e-01,  -2.26172939e-01,\n",
       "         6.84684664e-02,   4.97157216e-01,   2.08740473e-01,\n",
       "         2.73540497e-01,   2.66548060e-03,  -1.49608478e-01,\n",
       "        -8.36742893e-02,  -1.46228541e-02,  -4.39940602e-01,\n",
       "         6.64345771e-02,  -1.07857049e-01,   1.42971009e-01,\n",
       "        -4.59211528e-01,   1.69700205e-01,   5.95320582e-01,\n",
       "        -1.99764952e-01,  -3.25701050e-02,   1.26501739e-01,\n",
       "        -1.04102187e-01,  -6.99892223e-01,   1.37701910e-02,\n",
       "        -1.18889354e-01,  -2.33929321e-01,  -3.58770996e-01,\n",
       "        -2.37076640e-01,   4.48607475e-01,   1.20104343e-01,\n",
       "         5.17350733e-01,  -7.83679599e-04,   2.03610852e-01,\n",
       "         1.67940930e-01,  -4.02731061e-01,  -8.81245553e-01,\n",
       "        -1.37067050e-01,  -2.90409625e-01,   2.16971859e-01,\n",
       "        -4.22496617e-01,   1.09822944e-01,   4.87792164e-01,\n",
       "         3.34491618e-02,  -8.04835036e-02,  -2.47016206e-01,\n",
       "        -1.68930274e-02,   7.69989341e-02,   3.11930209e-01,\n",
       "         2.34426111e-01,  -4.46855396e-01,  -9.07741711e-02,\n",
       "         6.19011521e-01,   5.72533980e-02,  -3.37463409e-01,\n",
       "        -1.96843699e-01,   6.07071161e-01,   3.03945124e-01,\n",
       "         7.41839781e-02,   2.84092695e-01,   3.86024863e-01,\n",
       "         4.25458163e-01,  -1.05177425e-02,   2.68027991e-01,\n",
       "        -5.90774775e-01,   3.32051873e-01,   7.40890875e-02,\n",
       "        -2.23718658e-01,  -9.87683162e-02,  -5.45767963e-01,\n",
       "        -1.06675476e-02,  -1.79374203e-01,  -8.91768157e-01,\n",
       "         1.86291620e-01,   8.05890071e-04,   1.16065018e-01,\n",
       "        -2.79451698e-01,  -4.17514622e-01,  -4.01633531e-01,\n",
       "         6.53188050e-01,   1.99763536e-01,  -7.12453425e-01,\n",
       "         2.08949268e-01,   7.39666998e-01,   3.02934080e-01,\n",
       "        -3.05657327e-01,   4.46321964e-01,   1.22907376e-02,\n",
       "        -1.05923206e-01], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([model[w] for w in fast_tokenize(X[0]) if w in model], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a set `X` array with 100 features. We can write a function to do this for us for any given string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_featurize(document, model):\n",
    "    return np.mean([model[w] for w in fast_tokenize(document) if w in model], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then featurize all of our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = [w2v_featurize(d, model) for d in X_train]\n",
    "X_test_w2v = [w2v_featurize(d, model) for d in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit and score the machine learning modle just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78749999999999998"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    "logit_model = logit_class.fit(X_train_w2v, y_train)\n",
    "logit_model.score(X_test_w2v, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about Heuser's model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77249999999999996"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v = [w2v_featurize(d, ecco_model) for d in X_train]\n",
    "X_test_w2v = [w2v_featurize(d, ecco_model) for d in X_test]\n",
    "logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    "logit_model = logit_class.fit(X_train_w2v, y_train)\n",
    "logit_model.score(X_test_w2v, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! But wait, what if we wanted to know *why* the model was making decisions. If we ask for the most postive coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77, 67, 88, 81, 15, 47, 57, 36, 90, 70])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(logit_model.coef_[0])[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([97, 96, 49, 87,  0, 52, 84, 42, 43,  1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(logit_model.coef_[0])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the *indices* for the important features. ***But what are these features now?***\n",
    "\n",
    "---\n",
    "\n",
    "Note that using our novels w2v model was not as accurate as a BoW tfidf method. That should be expected given movie review language is likely ***VERY*** different from our novel corpus. And our novel corpus likely didn't even have entries for a lot of the words used in our movie reviews corpus.\n",
    "\n",
    "For modern English, most people look for Stanford's [GloVe](https://nlp.stanford.edu/projects/glove/) model. This was trained on 6 billion tokens from Wikipedia and Gigaword! Quite a step up from 150 novels. Even the smallest model is a bit large to be working with on our cloud server, but using this model and the code below, you can see it's power:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> os.system('python -m gensim.scripts.glove2word2vec -i glove.6B.100d.txt -o glove.6B.100d.w2v.txt')\n",
    ">>> glove = gensim.models.KeyedVectors.load_word2vec_format('glove.6B.100d.w2v.txt')\n",
    "\n",
    ">>> X_train_glove = [w2v_featurize(d, glove) for d in X_train]\n",
    ">>> X_test_glove = [w2v_featurize(d, glove) for d in X_test]\n",
    "\n",
    ">>> logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    ">>> logit_model = logit_class.fit(X_train_glove, y_train)\n",
    ">>> logit_model.score(X_test_glove, y_test)\n",
    "\n",
    ".8125\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is not as accurate as our BoW *tfidf* method, there have been several applications and transformations of word embeddings that have proven to be more accurate than a BoW *tfidf* on general modern text corpora. And keep in mind, one of the most interesting parts of this is that it only uses 100 dimensions, i.e., we can get ~81% accuracy by reducing a movie review to only 100 different features (our BoW model had over 39000!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_transformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d8ecdd49129e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_transformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_transformed' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.13.1-py2.py3-none-any.whl (631kB)\n",
      "\u001b[K    100% |████████████████████████████████| 634kB 11.1MB/s a 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /srv/app/venv/lib/python3.6/site-packages (from textblob)\n",
      "Requirement already satisfied: six in /srv/app/venv/lib/python3.6/site-packages (from nltk>=3.1->textblob)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_blob = 'this movvie sucks. Cinetmetography was awesome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_object = TextBlob(my_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"this movvie sucks.\"), Sentence(\"Cinetmetography was awesome\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in blob_object.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this movvie sucks.\n",
      "-0.3\n",
      "Cinetmetography was awesome\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for s in blob_object.sentences:\n",
    "    print(s)\n",
    "    print(s.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
